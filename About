Image Caption Generation is an innovative application of Natural Language Processing (NLP) integrated with Computer Vision, aiming to automate tasks such as social media content categorization. This project utilizes deep learning models, particularly Long Short-Term Memory (LSTM) networks, to generate descriptive captions for images. Leveraging the FLICKR8K dataset, consisting of 8000 unique images each paired with five descriptive sentences, this project explores the fusion of computer vision and NLP to bridge the semantic gap between visual content and natural language descriptions. The proposed system architecture employs Transfer Learning with the ResNet50 model for feature extraction and GloVe word embeddings for caption generation. Through this approach, the project aims to contribute to the advancement of image understanding and description generation in AI systems.
